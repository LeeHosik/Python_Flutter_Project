{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib.request as req\n",
    "from urllib import parse\n",
    "from flask import Flask, jsonify, request, render_template\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news():\n",
    "    url = 'http://www.ccnnews.co.kr/news/articleList.html?view_type=sm'\n",
    "    cungAllNewsurl = 'http://www.ccnnews.co.kr'\n",
    "    res = req.urlopen(url)\n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    links = soup.select(\".list-titles a\")\n",
    "\n",
    "    newstitles = []\n",
    "    newsLinks = []\n",
    "    errorList = []\n",
    "    setJSONList = []\n",
    "    i = 0\n",
    "    for link in links:\n",
    "        try:  \n",
    "            newstitles.append(link.text)\n",
    "            newsLinks.append(cungAllNewsurl+link.attrs['href'])\n",
    "        except: errorList.append(f'Error number : {str(link)} newsTitle :{link.text}')\n",
    "        else:\n",
    "            setJSONList.append({newstitles[i]:newsLinks[i]})\n",
    "            i += 1\n",
    "\n",
    "    # return jsonify({\n",
    "        # 'result' : setJSONList\n",
    "    return setJSONList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{\"부여군, 남면‧초촌면 기초생활거점 조성사업 추진 ‘시동'\": 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286391'},\n",
       " {'(사)금산군기업인협회, 제2대 신상오 회장 취임': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286390'},\n",
       " {'계룡시, 관광자원 활용한 공정여행 프로그램 운영': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286388'},\n",
       " {'홍성군, 서해 KTX 시대 맞이 신바람 관광택시 ‘시동’': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286389'},\n",
       " {'서천군, 청년 구직 지원에 1억 5000만원 투입': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286387'},\n",
       " {'예산군, ‘2022년 하반기 적극행정 우수사례’ 군민투표 실시': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286386'},\n",
       " {'안전한 관광지 예산군, 숙박시설 불공정 행위 집중 점검': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286384'},\n",
       " {'태안군, ‘응급처치 안전 교육’ 큰 호응': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286383'},\n",
       " {'태안군, 3월 2일부터 ‘기본형 공익직불금’ 신청 접수': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286382'},\n",
       " {'태안군, 상반기 ‘혁신대학’ 운영 돌입': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286381'},\n",
       " {'가세로 태안군수, 27일 ‘후계농업경영인 및 여성농업인 군 연합회장 이·취임식’ 참석': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286380'},\n",
       " {'한국타이어 ‘아이온(iON)’, 포뮬러 E ‘2023 케이프타운 E-PRIX’ 대회 예열 마쳐': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286379'},\n",
       " {\"충남대학교병원·㈜드림씨아이에스, 바이오헬스케어사업 활성화 '맞손'\": 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286378'},\n",
       " {'예산군, 서울역 예가정성 브랜드 홍보 판매점 개점': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286376'},\n",
       " {\"오성환 당진시장,\\xa027일 '3월 통합공유회의 주재'\": 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286375'},\n",
       " {'대전평생학습관, 문화예술공연 참가 단체 공모': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286373'},\n",
       " {'대전교육청, ‘위(Wee)센터 정신과 자문의’ 운영': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286371'},\n",
       " {'KAIST, 퓨처모빌리티 기술교류회': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286370'},\n",
       " {\"'22년 전 국민은행 강도살인' 이승만·이정학 모두 항소\": 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286367'},\n",
       " {'서산문화복지센터 청소년동아리, 기부천사들의 활약': 'http://www.ccnnews.co.kr/news/articleView.html?idxno=286366'},\n",
       " {'': 'http://www.ccnnews.co.kr'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# http://www.kwnews.co.kr/search?search=%EC%9D%98%EC%9B%90"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news():\n",
    "    url = 'http://www.kwnews.co.kr/search?search='\n",
    "    searchValue = ''\n",
    "    cungAllNewsurl = 'http://www.ccnnews.co.kr'\n",
    "    res = req.urlopen(url)\n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "    links = soup.select(\".list-titles a\")\n",
    "\n",
    "    newstitles = []\n",
    "    newsLinks = []\n",
    "    errorList = []\n",
    "    setJSONList = []\n",
    "    i = 0\n",
    "    for link in links:\n",
    "        try:  \n",
    "            newstitles.append(link.text)\n",
    "            newsLinks.append(cungAllNewsurl+link.attrs['href'])\n",
    "        except: errorList.append(f'Error number : {str(link)} newsTitle :{link.text}')\n",
    "        else:\n",
    "            setJSONList.append({newstitles[i]:newsLinks[i]})\n",
    "            i += 1\n",
    "\n",
    "    # return jsonify({\n",
    "        # 'result' : setJSONList\n",
    "    return setJSONList\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news(str):\n",
    "    url = 'http://www.kwnews.co.kr/search?search='\n",
    "    originURL = 'http://www.kwnews.co.kr/'\n",
    "    searchValue = str\n",
    "    search = url+parse.quote(url+searchValue)\n",
    "    # searchValue = '의원'\n",
    "    res = req.urlopen(search)\n",
    "    # soup = BeautifulSoup(req.content.decode('euc-kr', 'replace'), 'html.parser')\n",
    "    soup = BeautifulSoup(res, \"html.parser\")\n",
    "\n",
    "    links = soup.select(\".search_list .title a\")\n",
    "\n",
    "    newstitles = []\n",
    "    newsLinks = []\n",
    "    errorList = []\n",
    "    setJSONList = []\n",
    "    i = 0\n",
    "    for link in links:\n",
    "        try:  \n",
    "            newstitles.append(link.text)\n",
    "            print(link.text)\n",
    "            newsLinks.append(originURL+link.attrs['href'])\n",
    "        except: errorList.append(f'Error number : {str(link)} newsTitle :{link.text}')\n",
    "        else:\n",
    "            setJSONList.append({newstitles[i]:newsLinks[i]})\n",
    "            i += 1\n",
    "\n",
    "    # return jsonify({\n",
    "        # 'result' : setJSONList\n",
    "    return setJSONList  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news('의원')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "ename": "SelectorSyntaxError",
     "evalue": "Invalid character '/' position 0\n  line 1:\n//*[@id=\"search_list\"]/li[1]/div[2]/p[1]\n^",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSelectorSyntaxError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[112], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m soup \u001b[39m=\u001b[39m BeautifulSoup(res, \u001b[39m\"\u001b[39m\u001b[39mhtml.parser\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      9\u001b[0m \u001b[39m# links = soup.select(\"ul#search_list li\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39m# links = soup.select(\".section.pr10 .arl_008_list\")\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[39m# links = soup.select(\"#search_list p.title\")\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m links \u001b[39m=\u001b[39m soup\u001b[39m.\u001b[39;49mselect(\u001b[39m'\u001b[39;49m\u001b[39m//*[@id=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39msearch_list\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m]/li[1]/div[2]/p[1]\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m     13\u001b[0m \u001b[39m# links = soup.findAll(\"ul#search_list\")\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \n\u001b[1;32m     15\u001b[0m \u001b[39m# links = soup.select('.arl_008_list .title')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39m# for link in links:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# print(link)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m links\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/bs4/element.py:1992\u001b[0m, in \u001b[0;36mTag.select\u001b[0;34m(self, selector, namespaces, limit, **kwargs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m \u001b[39mif\u001b[39;00m soupsieve \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1988\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1989\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot execute CSS selectors because the soupsieve package is not installed.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1990\u001b[0m     )\n\u001b[0;32m-> 1992\u001b[0m results \u001b[39m=\u001b[39m soupsieve\u001b[39m.\u001b[39;49mselect(selector, \u001b[39mself\u001b[39;49m, namespaces, limit, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1994\u001b[0m \u001b[39m# We do this because it's more consistent and because\u001b[39;00m\n\u001b[1;32m   1995\u001b[0m \u001b[39m# ResultSet.__getattr__ has a helpful error message.\u001b[39;00m\n\u001b[1;32m   1996\u001b[0m \u001b[39mreturn\u001b[39;00m ResultSet(\u001b[39mNone\u001b[39;00m, results)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/soupsieve/__init__.py:144\u001b[0m, in \u001b[0;36mselect\u001b[0;34m(select, tag, namespaces, limit, flags, custom, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mselect\u001b[39m(\n\u001b[1;32m    133\u001b[0m     select: \u001b[39mstr\u001b[39m,\n\u001b[1;32m    134\u001b[0m     tag: \u001b[39m'\u001b[39m\u001b[39mbs4.Tag\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any\n\u001b[1;32m    141\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39m'\u001b[39m\u001b[39mbs4.Tag\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    142\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Select the specified tags.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcompile\u001b[39;49m(select, namespaces, flags, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\u001b[39m.\u001b[39mselect(tag, limit)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/soupsieve/__init__.py:67\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(pattern, namespaces, flags, custom, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot process \u001b[39m\u001b[39m'\u001b[39m\u001b[39mcustom\u001b[39m\u001b[39m'\u001b[39m\u001b[39m argument on a compiled selector list\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     65\u001b[0m     \u001b[39mreturn\u001b[39;00m pattern\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m cp\u001b[39m.\u001b[39;49m_cached_css_compile(pattern, ns, cs, flags)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/soupsieve/css_parser.py:218\u001b[0m, in \u001b[0;36m_cached_css_compile\u001b[0;34m(pattern, namespaces, custom, flags)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Cached CSS compile.\"\"\"\u001b[39;00m\n\u001b[1;32m    215\u001b[0m custom_selectors \u001b[39m=\u001b[39m process_custom(custom)\n\u001b[1;32m    216\u001b[0m \u001b[39mreturn\u001b[39;00m cm\u001b[39m.\u001b[39mSoupSieve(\n\u001b[1;32m    217\u001b[0m     pattern,\n\u001b[0;32m--> 218\u001b[0m     CSSParser(\n\u001b[1;32m    219\u001b[0m         pattern,\n\u001b[1;32m    220\u001b[0m         custom\u001b[39m=\u001b[39;49mcustom_selectors,\n\u001b[1;32m    221\u001b[0m         flags\u001b[39m=\u001b[39;49mflags\n\u001b[1;32m    222\u001b[0m     )\u001b[39m.\u001b[39;49mprocess_selectors(),\n\u001b[1;32m    223\u001b[0m     namespaces,\n\u001b[1;32m    224\u001b[0m     custom,\n\u001b[1;32m    225\u001b[0m     flags\n\u001b[1;32m    226\u001b[0m )\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/soupsieve/css_parser.py:1159\u001b[0m, in \u001b[0;36mCSSParser.process_selectors\u001b[0;34m(self, index, flags)\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess_selectors\u001b[39m(\u001b[39mself\u001b[39m, index: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, flags: \u001b[39mint\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m ct\u001b[39m.\u001b[39mSelectorList:\n\u001b[1;32m   1157\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Process selectors.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparse_selectors(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mselector_iter(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpattern), index, flags)\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/soupsieve/css_parser.py:985\u001b[0m, in \u001b[0;36mCSSParser.parse_selectors\u001b[0;34m(self, iselector, index, flags)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    984\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 985\u001b[0m         key, m \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(iselector)\n\u001b[1;32m    987\u001b[0m         \u001b[39m# Handle parts\u001b[39;00m\n\u001b[1;32m    988\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mat_rule\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/soupsieve/css_parser.py:1152\u001b[0m, in \u001b[0;36mCSSParser.selector_iter\u001b[0;34m(self, pattern)\u001b[0m\n\u001b[1;32m   1150\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1151\u001b[0m             msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mInvalid character \u001b[39m\u001b[39m{!r}\u001b[39;00m\u001b[39m position \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(c, index)\n\u001b[0;32m-> 1152\u001b[0m         \u001b[39mraise\u001b[39;00m SelectorSyntaxError(msg, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpattern, index)\n\u001b[1;32m   1153\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdebug:  \u001b[39m# pragma: no cover\u001b[39;00m\n\u001b[1;32m   1154\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m## END PARSING\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mSelectorSyntaxError\u001b[0m: Invalid character '/' position 0\n  line 1:\n//*[@id=\"search_list\"]/li[1]/div[2]/p[1]\n^"
     ]
    }
   ],
   "source": [
    "url = 'http://www.kwnews.co.kr/search?search='\n",
    "originURL = 'http://www.kwnews.co.kr/'\n",
    "searchValue = '의원'\n",
    "search = url+parse.quote(url+searchValue)\n",
    "# searchValue = '의원'\n",
    "res = req.urlopen(search)\n",
    "# soup = BeautifulSoup(req.content.decode('euc-kr', 'replace'), 'html.parser')\n",
    "soup = BeautifulSoup(res, \"html.parser\")\n",
    "# links = soup.select(\"ul#search_list li\")\n",
    "# links = soup.select(\".section.pr10 .arl_008_list\")\n",
    "# links = soup.select(\"#search_list p.title\")\n",
    "links = soup.select_one('//*[@id=\"search_list\"]/li[1]/div[2]/p[1]')\n",
    "# links = soup.findAll(\"ul#search_list\")\n",
    "\n",
    "# links = soup.select('.arl_008_list .title')\n",
    "\n",
    "# links2 = soup.find('div', id = 'search_list')\n",
    "# links1 = links2.select('.title a')\n",
    "# links1 = links2.select('a')\n",
    "# links = soup.select(\".search_list .title a\")\n",
    "\n",
    "# for link in links:\n",
    "# print(link)\n",
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d864e386a55a2cee39c31bc0e2325312cb68f97ec75faaaf5382620c119f58c5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
